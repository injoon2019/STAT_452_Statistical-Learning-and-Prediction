### Get the model's SSE
this.SSE = this.nnet$value
this.MSE = this.nnet$value / nrow(X.train)
### Store results. We have to use double square brackets when storing or
### retrieving from a list.
all.SSEs[i] = this.SSE
all.MSEs[i] = this.MSE
all.nnets[[i]] = this.nnet
}
all.MSEs
### Get the best model. We have to use double square brackets when storing or
### retrieving from a list.
# ind.best = which.min(all.SSEs)
# fit.nnet.best = all.nnets[[ind.best]]
ind.best = which.min(all.SSEs)
fit.nnet.best = all.nnets[[ind.best]]
x1 <- seq(from=2.3, to=20.7, by=.5)
x2 = seq(from=57, to=97, by=.5)
xy1 <- data.frame(expand.grid(wind=x1, temp=x2))
#pred.nnet = predict(fit.nnet.best, X.valid)
# pred.nnet = predict(fit.nnet.best, X.valid)
# MSPE.nnet = get.MSPE(Y.valid, pred.nnet)
# pred2 <- predict(pred.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
pred2 <- predict(fit.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="Wind", ylab="Temp",
zlab="Ozone")
points3d(data$Ozone ~ data$Wind + data$Temp, col="blue")
all.SSEs = rep(0, times = 20)
all.MSEs = rep(0, times = 20)
all.nnets = list(1:20)
for(i in 1:n.nnets){
### Fit model. We can set the input "trace" to FALSE to suppress the
### printed output from the nnet() function.
this.nnet = nnet(y = Y.train, x = X.train[,c(3,4)], linout = TRUE, size = n.hidden,
decay = shrink, maxit = 500, trace = FALSE)
### Get the model's SSE
this.SSE = this.nnet$value
this.MSE = this.nnet$value / nrow(X.train)
### Store results. We have to use double square brackets when storing or
### retrieving from a list.
all.SSEs[i] = this.SSE
all.MSEs[i] = this.MSE
all.nnets[[i]] = this.nnet
}
all.MSEs
### Get the best model. We have to use double square brackets when storing or
### retrieving from a list.
# ind.best = which.min(all.SSEs)
# fit.nnet.best = all.nnets[[ind.best]]
ind.best = which.min(all.SSEs)
fit.nnet.best = all.nnets[[ind.best]]
x1 <- seq(from=2.3, to=20.7, by=.5)
x2 = seq(from=57, to=97, by=.5)
xy1 <- data.frame(expand.grid(wind=x1, temp=x2))
#pred.nnet = predict(fit.nnet.best, X.valid)
# pred.nnet = predict(fit.nnet.best, X.valid)
# MSPE.nnet = get.MSPE(Y.valid, pred.nnet)
# pred2 <- predict(pred.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
pred2 <- predict(fit.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="Wind", ylab="Temp",
zlab="Ozone")
points3d(data$Ozone ~ data$Wind + data$Temp, col="blue")
n.hidden = 6
shrink = 1
fit.nnet = nnet(y = Y.train, x = X.train[,c(3,4)], linout = TRUE, size = n.hidden,
decay = shrink, maxit = 500)
n.nnets = 20 # Number of times to re-fit
### Container for SSEs
all.SSEs = rep(0, times = 20)
all.MSEs = rep(0, times = 20)
all.nnets = list(1:20)
for(i in 1:n.nnets){
### Fit model. We can set the input "trace" to FALSE to suppress the
### printed output from the nnet() function.
this.nnet = nnet(y = Y.train, x = X.train[,c(3,4)], linout = TRUE, size = n.hidden,
decay = shrink, maxit = 500, trace = FALSE)
### Get the model's SSE
this.SSE = this.nnet$value
this.MSE = this.nnet$value / nrow(X.train)
### Store results. We have to use double square brackets when storing or
### retrieving from a list.
all.SSEs[i] = this.SSE
all.MSEs[i] = this.MSE
all.nnets[[i]] = this.nnet
}
all.MSEs
### Get the best model. We have to use double square brackets when storing or
### retrieving from a list.
# ind.best = which.min(all.SSEs)
# fit.nnet.best = all.nnets[[ind.best]]
ind.best = which.min(all.SSEs)
fit.nnet.best = all.nnets[[ind.best]]
x1 <- seq(from=2.3, to=20.7, by=.5)
x2 = seq(from=57, to=97, by=.5)
xy1 <- data.frame(expand.grid(wind=x1, temp=x2))
#pred.nnet = predict(fit.nnet.best, X.valid)
# pred.nnet = predict(fit.nnet.best, X.valid)
# MSPE.nnet = get.MSPE(Y.valid, pred.nnet)
# pred2 <- predict(pred.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
pred2 <- predict(fit.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="Wind", ylab="Temp",
zlab="Ozone")
points3d(data$Ozone ~ data$Wind + data$Temp, col="blue")
n.hidden = 6
shrink = 1
fit.nnet = nnet(y = Y.train, x = X.train[,c(3,4)], linout = TRUE, size = n.hidden,
decay = shrink, maxit = 500)
n.nnets = 20 # Number of times to re-fit
### Container for SSEs
all.SSEs = rep(0, times = 20)
all.MSEs = rep(0, times = 20)
all.nnets = list(1:20)
for(i in 1:n.nnets){
### Fit model. We can set the input "trace" to FALSE to suppress the
### printed output from the nnet() function.
this.nnet = nnet(y = Y.train, x = X.train[,c(3,4)], linout = TRUE, size = n.hidden,
decay = shrink, maxit = 500, trace = FALSE)
### Get the model's SSE
this.SSE = this.nnet$value
this.MSE = this.nnet$value / nrow(X.train)
### Store results. We have to use double square brackets when storing or
### retrieving from a list.
all.SSEs[i] = this.SSE
all.MSEs[i] = this.MSE
all.nnets[[i]] = this.nnet
}
all.MSEs
### Get the best model. We have to use double square brackets when storing or
### retrieving from a list.
# ind.best = which.min(all.SSEs)
# fit.nnet.best = all.nnets[[ind.best]]
ind.best = which.min(all.SSEs)
fit.nnet.best = all.nnets[[ind.best]]
x1 <- seq(from=2.3, to=20.7, by=.5)
x2 = seq(from=57, to=97, by=.5)
xy1 <- data.frame(expand.grid(wind=x1, temp=x2))
#pred.nnet = predict(fit.nnet.best, X.valid)
# pred.nnet = predict(fit.nnet.best, X.valid)
# MSPE.nnet = get.MSPE(Y.valid, pred.nnet)
# pred2 <- predict(pred.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
pred2 <- predict(fit.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="Wind", ylab="Temp",
zlab="Ozone")
points3d(data$Ozone ~ data$Wind + data$Temp, col="blue")
n.hidden = 6
shrink = 1
fit.nnet = nnet(y = Y.train, x = X.train[,c(3,4)], linout = TRUE, size = n.hidden,
decay = shrink, maxit = 500)
n.nnets = 20 # Number of times to re-fit
### Container for SSEs
all.SSEs = rep(0, times = 20)
all.MSEs = rep(0, times = 20)
all.nnets = list(1:20)
for(i in 1:n.nnets){
### Fit model. We can set the input "trace" to FALSE to suppress the
### printed output from the nnet() function.
this.nnet = nnet(y = Y.train, x = X.train[,c(3,4)], linout = TRUE, size = n.hidden,
decay = shrink, maxit = 500, trace = FALSE)
### Get the model's SSE
this.SSE = this.nnet$value
this.MSE = this.nnet$value / nrow(X.train)
### Store results. We have to use double square brackets when storing or
### retrieving from a list.
all.SSEs[i] = this.SSE
all.MSEs[i] = this.MSE
all.nnets[[i]] = this.nnet
}
all.MSEs
### Get the best model. We have to use double square brackets when storing or
### retrieving from a list.
# ind.best = which.min(all.SSEs)
# fit.nnet.best = all.nnets[[ind.best]]
ind.best = which.min(all.SSEs)
fit.nnet.best = all.nnets[[ind.best]]
x1 <- seq(from=2.3, to=20.7, by=.5)
x2 = seq(from=57, to=97, by=.5)
xy1 <- data.frame(expand.grid(wind=x1, temp=x2))
#pred.nnet = predict(fit.nnet.best, X.valid)
# pred.nnet = predict(fit.nnet.best, X.valid)
# MSPE.nnet = get.MSPE(Y.valid, pred.nnet)
# pred2 <- predict(pred.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
pred2 <- predict(fit.nnet ,newdata=rescale(xy1, X.valid.raw[,c(3,4)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="Wind", ylab="Temp",
zlab="Ozone")
points3d(data$Ozone ~ data$Wind + data$Temp, col="blue")
prostate <-  read.table("Prostate.csv",
header=TRUE, sep=",", na.strings=" ")
#head(prostate)
# Here I will make a small test set so I can show how to compute test/validation error.
# Selecting 20 obs for test set
set.seed(2371903)
reorder = sample.int(n=nrow(prostate))
reorder
set = ifelse(test=(reorder > 20), yes=1, no=2)
set
library(nnet)
############
## Computing will work better if explanatories are rescaled to lie in [0,1]
# Function below scales values in a single object according to its own min and max.
#   Can apply it to training data, but validation set needs to be scaled
#   BY THE TRAINING SET MIN AND MAX!
############
# Use min and max from each column of x2 to rescale
#   corresponding columns of x1.
rescale <- function(x1,x2){
for(col in 1:ncol(x1)){
a <- min(x2[,col])
b <- max(x2[,col])
x1[,col] <- (x1[,col]-a)/(b-a)
}
x1
}
# Split data into training and test data and store as matrices.
y.1 <- as.matrix(prostate[set==1,9])
x.1.unscaled <- as.matrix(prostate[set==1,-9]) # Original data set 1
x.1 <- rescale(x.1.unscaled, x.1.unscaled) #scaled data set 1
summary(x.1.unscaled)
summary(x.1)
#Test
y.2 <- as.matrix(prostate[set==2,9])
x.2.unscaled <- as.matrix(prostate[set==2,-9]) # Original data set 2
x.2 = rescale(x.2.unscaled, x.1.unscaled)
summary(x.2)
nn.1 <- nnet(y=y.1, x=x.1[,c(1,8)], linout=TRUE, size=1, maxit=1000)
p.nn.1 <-predict(nn.1, newdata=x.2)
#(MSPR.nn1 <- mean((y.2 - p.nn.1)^2))
(MSE.nn1 <- nn.1$value/nrow(x.1))
plot(x=y.2, y=p.nn.1, main="Predicted vs. Actual")
abline(a=0,b=1)
# Shows estimated weights, in case you care
summary(nn.1)
# Plot the surface
library(rgl)
x1 <- seq(from=-2, to=4, by=.05)
x2 = seq(from=0, to=100, by=.5)
xy1 <- data.frame(expand.grid(lcavol=x1, pgg45=x2))
pred2 <- predict(nn.1 ,newdata=rescale(xy1,x.1.unscaled[,c(1,8)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="lcavol", ylab="pgg45",
zlab="Predicted lpsa")
points3d(prostate$lpsa ~ prostate$lcavol + prostate$pgg45, col="blue")
nn.3.1 <- nnet(y=y.1, x=x.1[,c(1,8)], linout=TRUE, size=3,
decay=0.1,maxit=500)
p.nn.3.1 <-predict(nn.3.1, newdata=x.2)
(MSPR.nn3.1 <- mean((y.2 - p.nn.3.1)^2))
(MSE.nn3.1 <- nn.3.1$value/nrow(x.1))
plot(x=y.2, y=p.nn.3.1, main="Predicted vs. Actual")
abline(a=0,b=1)
# Shows estimated weights, in case you care
summary(nn.3.1)
# Plot the surface
library(rgl)
x1 <- seq(from=-2, to=4, by=.05)
x2 = seq(from=0, to=100, by=.5)
xy1 <- data.frame(expand.grid(lcavol=x1, pgg45=x2))
pred2 <- predict(nn.3.1 ,newdata=rescale(xy1,x.1.unscaled[,c(1,8)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="lcavol", ylab="pgg45",
zlab="Predicted lpsa")
points3d(prostate$lpsa ~ prostate$lcavol + prostate$pgg45, col="blue")
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="lcavol", ylab="pgg45",
zlab="Predicted lpsa")
prostate <-  read.table("Prostate.csv",
header=TRUE, sep=",", na.strings=" ")
setwd("C:/Users/injoo/OneDrive/Desktop/SFU/STAT 452/Lecture Note/Week 8")
prostate <-  read.table("Prostate.csv",
header=TRUE, sep=",", na.strings=" ")
set.seed(2371903)
reorder = sample.int(n=nrow(prostate))
reorder
set = ifelse(test=(reorder > 20), yes=1, no=2)
set
library(nnet)
rescale <- function(x1,x2){
for(col in 1:ncol(x1)){
a <- min(x2[,col])
b <- max(x2[,col])
x1[,col] <- (x1[,col]-a)/(b-a)
}
x1
}
# Split data into training and test data and store as matrices.
y.1 <- as.matrix(prostate[set==1,9])
x.1.unscaled <- as.matrix(prostate[set==1,-9]) # Original data set 1
x.1 <- rescale(x.1.unscaled, x.1.unscaled) #scaled data set 1
summary(x.1.unscaled)
summary(x.1)
#Test
y.2 <- as.matrix(prostate[set==2,9])
x.2.unscaled <- as.matrix(prostate[set==2,-9]) # Original data set 2
x.2 = rescale(x.2.unscaled, x.1.unscaled)
summary(x.2)
nn.1 <- nnet(y=y.1, x=x.1[,c(1,8)], linout=TRUE, size=1, maxit=1000)
p.nn.1 <-predict(nn.1, newdata=x.2)
#(MSPR.nn1 <- mean((y.2 - p.nn.1)^2))
(MSE.nn1 <- nn.1$value/nrow(x.1))
plot(x=y.2, y=p.nn.1, main="Predicted vs. Actual")
abline(a=0,b=1)
# Shows estimated weights, in case you care
summary(nn.1)
# Plot the surface
library(rgl)
x1 <- seq(from=-2, to=4, by=.05)
x2 = seq(from=0, to=100, by=.5)
xy1 <- data.frame(expand.grid(lcavol=x1, pgg45=x2))
pred2 <- predict(nn.1 ,newdata=rescale(xy1,x.1.unscaled[,c(1,8)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="lcavol", ylab="pgg45",
zlab="Predicted lpsa")
points3d(prostate$lpsa ~ prostate$lcavol + prostate$pgg45, col="blue")
nn.3.1 <- nnet(y=y.1, x=x.1[,c(1,8)], linout=TRUE, size=3,
decay=0.1,maxit=500)
p.nn.3.1 <-predict(nn.3.1, newdata=x.2)
(MSPR.nn3.1 <- mean((y.2 - p.nn.3.1)^2))
(MSE.nn3.1 <- nn.3.1$value/nrow(x.1))
plot(x=y.2, y=p.nn.3.1, main="Predicted vs. Actual")
abline(a=0,b=1)
# Shows estimated weights, in case you care
summary(nn.3.1)
# Plot the surface
library(rgl)
x1 <- seq(from=-2, to=4, by=.05)
x2 = seq(from=0, to=100, by=.5)
xy1 <- data.frame(expand.grid(lcavol=x1, pgg45=x2))
pred2 <- predict(nn.3.1 ,newdata=rescale(xy1,x.1.unscaled[,c(1,8)]))
surface2 = matrix(pred2, nrow=length(x1))
open3d()
persp3d(x = x1, y = x2,
z = surface2, col = "orange", xlab="lcavol", ylab="pgg45",
zlab="Predicted lpsa")
points3d(prostate$lpsa ~ prostate$lcavol + prostate$pgg45, col="blue")
library(caret)
# This function will do min-max scaling internally with preProcess="range"
# Need to use y as a numeric vector and not a matrix.
# Can change numbers used in tune.Grid as needed.
# Default is 25 bootstrap reps
# Can be changed by adding
# trcon = trainControl(method=..., number=..., repeats=...)
#  Can do method= "boot", "cv", "repeatedcv", "LOOCV", and several others
#  number= is number of boot reps or cv folds
#  repeats= number of CV replicates
#  returnResamp="all" retains the error measures from each split.
#Specify 5-fold CV run twice
trcon = trainControl(method="repeatedcv", number=5, repeats=2,
returnResamp="all")
parmgrid = expand.grid(size=c(1,2,4,6),decay= c(0,.1, .5, 1))
tuned.nnet <- train(x=prostate[,-9], y=prostate[,9], method="nnet",
trace=FALSE, linout=TRUE,
trControl=trcon, preProcess="range",
tuneGrid = parmgrid)
tuned.nnet
names(tuned.nnet)
tuned.nnet$bestTune
#If I want to make plots, I need to rearrange the resamples
(resamp.caret = tuned.nnet$resample[,-c(2,3)])
library(reshape)
RMSPE.caret = reshape(resamp.caret, direction="wide", v.names="RMSE",
idvar=c("size","decay"), timevar="Resample")
# Plot results.
siz.dec <- paste("NN",RMSPE.caret[,1],"/",RMSPE.caret[,2])
x11(pointsize=10)
boxplot(x=as.matrix(RMSPE.caret[,-c(1,2)]), use.cols=FALSE, names=siz.dec,
las=2, main="caret Root-MSPE boxplot for various NNs")
# Plot RELATIVE results.
lowt = apply(RMSPE.caret[,-c(1,2)], 2, min)
x11(pointsize=10)
boxplot(x=t(as.matrix(RMSPE.caret[,-c(1,2)]))/lowt, las=2,
names=siz.dec)
#Focused
x11(pointsize=10)
boxplot(x=t(as.matrix(RMSPE.caret[,-c(1,2)]))/lowt, las=2,
names=siz.dec, ylim=c(1,2))
R=2
V=5
relMSPE = t(RMSPE.caret[,-c(1,2)])/lowt
(RRMSPE = apply(X=relMSPE, MARGIN=2, FUN=mean))
(RRMSPE.sd = apply(X=relMSPE, MARGIN=2, FUN=sd))
RRMSPE.CIl = RRMSPE - qt(p=.975, df=R*V-1)*RRMSPE.sd/sqrt(R*V)
RRMSPE.CIu = RRMSPE + qt(p=.975, df=R*V-1)*RRMSPE.sd/sqrt(R*V)
(all.rrcv = cbind(RMSPE.caret[,1:2],round(sqrt(cbind(RRMSPE,RRMSPE.CIl, RRMSPE.CIu)),2)))
all.rrcv[order(RRMSPE),]
library(reshape)
RMSPE.caret
trcon = trainControl(method="repeatedcv", number=5, repeats=2,
returnResamp="all")
parmgrid = expand.grid(size=c(1,3,5,7,8),decay= c(0.001, .1, .5, 1 ,2))
tuned.nnet <- train(x=airquality[,-1], y=airquality[,1], method="nnet",
trace=FALSE, linout=TRUE,
trControl=trcon, preProcess="range",
tuneGrid = parmgrid)
data = na.omit(airquality[, 1:4])
tuned.nnet <- train(x=data[,-1], y=data[,1], method="nnet",
trace=FALSE, linout=TRUE,
trControl=trcon, preProcess="range",
tuneGrid = parmgrid)
tuned.nnet
names(tuned.nnet)
tuned.nnet$bestTune
#If I want to make plots, I need to rearrange the resamples
(resamp.caret = tuned.nnet$resample[,-c(2,3)])
RMSPE.caret = reshape(resamp.caret, direction="wide", v.names="RMSE",
idvar=c("size","decay"), timevar="Resample")
# Plot results.
siz.dec <- paste("NN",RMSPE.caret[,1],"/",RMSPE.caret[,2])
x11(pointsize=10)
boxplot(x=as.matrix(RMSPE.caret[,-c(1,2)]), use.cols=FALSE, names=siz.dec,
las=2, main="caret Root-MSPE boxplot for various NNs")
# Plot RELATIVE results.
lowt = apply(RMSPE.caret[,-c(1,2)], 2, min)
x11(pointsize=10)
boxplot(x=t(as.matrix(RMSPE.caret[,-c(1,2)]))/lowt, las=2,
names=siz.dec)
#Focused
x11(pointsize=10)
boxplot(x=t(as.matrix(RMSPE.caret[,-c(1,2)]))/lowt, las=2,
names=siz.dec, ylim=c(1,2))
R=2
V=5
relMSPE = t(RMSPE.caret[,-c(1,2)])/lowt
(RRMSPE = apply(X=relMSPE, MARGIN=2, FUN=mean))
(RRMSPE.sd = apply(X=relMSPE, MARGIN=2, FUN=sd))
RRMSPE.CIl = RRMSPE - qt(p=.975, df=R*V-1)*RRMSPE.sd/sqrt(R*V)
RRMSPE.CIu = RRMSPE + qt(p=.975, df=R*V-1)*RRMSPE.sd/sqrt(R*V)
(all.rrcv = cbind(RMSPE.caret[,1:2],round(sqrt(cbind(RRMSPE,RRMSPE.CIl, RRMSPE.CIu)),2)))
all.rrcv[order(RRMSPE),]
#Specify 5-fold CV run twice
trcon = trainControl(method="repeatedcv", number=5, repeats=2,
returnResamp="all")
parmgrid = expand.grid(size=c(1,3,5,7,8),decay= c(0.001, .1, .5, 1 ,2))
tuned.nnet <- train(x=data[,-1], y=data[,1], method="nnet",
trace=FALSE, linout=TRUE,
trControl=trcon, preProcess="range",
tuneGrid = parmgrid)
tuned.nnet
names(tuned.nnet)
tuned.nnet$bestTune
(resamp.caret = tuned.nnet$resample[,-c(2,3)])
library(reshape)
RMSPE.caret = reshape(resamp.caret, direction="wide", v.names="RMSE",
idvar=c("size","decay"), timevar="Resample")
RMSPE.caret
siz.dec <- paste("NN",RMSPE.caret[,1],"/",RMSPE.caret[,2])
x11(pointsize=10)
boxplot(x=as.matrix(RMSPE.caret[,-c(1,2)]), use.cols=FALSE, names=siz.dec,
las=2, main="caret Root-MSPE boxplot for various NNs")
# Plot results.
siz.dec <- paste("NN",RMSPE.caret[,1],"/",RMSPE.caret[,2])
x11(pointsize=10)
boxplot(x=as.matrix(RMSPE.caret[,-c(1,2)]), use.cols=FALSE, names=siz.dec,
las=2, main="caret Root-MSPE boxplot for various NNs")
# Plot results.
siz.dec <- paste("NN",RMSPE.caret[,1],"/",RMSPE.caret[,2])
x11(pointsize=10)
boxplot(x=as.matrix(RMSPE.caret[,-c(1,2)]), use.cols=FALSE, names=siz.dec,
las=2, main="caret Root-MSPE boxplot for various NNs")
# Plot RELATIVE results.
lowt = apply(RMSPE.caret[,-c(1,2)], 2, min)
x11(pointsize=10)
boxplot(x=t(as.matrix(RMSPE.caret[,-c(1,2)]))/lowt, las=2,
names=siz.dec)
boxplot(x=t(as.matrix(RMSPE.caret[,-c(1,2)]))/lowt, las=2,
names=siz.dec)
R=2
V=5
relMSPE = t(RMSPE.caret[,-c(1,2)])/lowt
(RRMSPE = apply(X=relMSPE, MARGIN=2, FUN=mean))
(RRMSPE.sd = apply(X=relMSPE, MARGIN=2, FUN=sd))
RRMSPE.CIl = RRMSPE - qt(p=.975, df=R*V-1)*RRMSPE.sd/sqrt(R*V)
RRMSPE.CIu = RRMSPE + qt(p=.975, df=R*V-1)*RRMSPE.sd/sqrt(R*V)
(all.rrcv = cbind(RMSPE.caret[,1:2],round(sqrt(cbind(RRMSPE,RRMSPE.CIl, RRMSPE.CIu)),2)))
all.rrcv[order(RRMSPE),]
#Specify 5-fold CV run twice
trcon = trainControl(method="repeatedcv", number=5, repeats=2,
returnResamp="all")
parmgrid = expand.grid(size=c(1,3,5,7,9),decay= c(0.001, .1, .5, 1 ,2))
tuned.nnet <- train(x=data[,-1], y=data[,1], method="nnet",
trace=FALSE, linout=TRUE,
trControl=trcon, preProcess="range",
tuneGrid = parmgrid)
tuned.nnet
names(tuned.nnet)
tuned.nnet$bestTune
#If I want to make plots, I need to rearrange the resamples
(resamp.caret = tuned.nnet$resample[,-c(2,3)])
library(reshape)
RMSPE.caret = reshape(resamp.caret, direction="wide", v.names="RMSE",
idvar=c("size","decay"), timevar="Resample")
lowt = apply(RMSPE.caret[,-c(1,2)], 2, min)
boxplot(x=t(as.matrix(RMSPE.caret[,-c(1,2)]))/lowt, las=2,
names=siz.dec)
