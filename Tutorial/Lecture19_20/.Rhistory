set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
data.train = set1
data.valid = set2
Y.valid = data.valid[, 19]
### Rescale x1 using the means and SDs of x2
rescale <- function(x1,x2){
for(col in 1:ncol(x1)){
a <- min(x2[,col])
b <- max(x2[,col])
x1[,col] <- (x1[,col]-a)/(b-a)
}
x1
}
### Rescale our training and validation sets
data.train.scale = data.train
data.valid.scale = data.valid
data.train.scale[,-1] = rescale(data.train.scale[,-19], data.train[,-19])
data.valid.scale[,-1] = rescale(data.valid.scale[,-19], data.train[,-19])
summary(data.train.scale)
data.train.scale[,-19] = rescale(data.train.scale[,-19], data.train[,-19])
data.valid.scale[,-19] = rescale(data.valid.scale[,-19], data.train[,-19])
summary(data.train.scale)
vehdata = read.csv("vehicle.csv")
vehdata$class = factor(vehdata$class, labels=c("2D", "4D", "BUS", "VAN"))
set.seed(46685326, kind = "Mersenne-Twister")
perm <- sample (x= nrow ( vehdata ))
set1 <- vehdata [ which ( perm <= 3* nrow ( vehdata )/4) , ]
set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
data.train = set1
data.valid = set2
Y.valid = data.valid[, 19]
### Rescale x1 using the means and SDs of x2
rescale <- function(x1,x2){
for(col in 1:ncol(x1)){
a <- min(x2[,col])
b <- max(x2[,col])
x1[,col] <- (x1[,col]-a)/(b-a)
}
x1
}
### Rescale our training and validation sets
data.train.scale = data.train
data.valid.scale = data.valid
data.train.scale[,-19] = rescale(data.train.scale[,-19], data.train[,-19])
data.valid.scale[,-19] = rescale(data.valid.scale[,-19], data.train[,-19])
summary(data.train.scale)
summary(data.valid.scale)
head(data.train.scale, 3)
head(data.valid.scale, 3)
# (b) Run the logistic regression model using all explanatory variables.
### Fit a logistic regression model using the multinom() function from the
### nnet package.
fit.log.nnet = multinom(class ~ ., data = data.train.scale, maxit = 200)
summary(fit.log.nnet)
Anova(fit.log.nnet)
pred.class.1 <- predict(mod.fit, newdata=data.train.scale,
type="class")
pred.class.1 <- predict(fit.log.nnet, newdata=data.train.scale,
type="class")
pred.class.2 <- predict(fit.log.nnet, newdata=data.valid.scale,
type="class")
(mul.misclass.train <- mean(ifelse(pred.class.1 == set1$class,
yes=0, no=1)))
(mul.misclass.test <- mean(ifelse(pred.class.2 == set2$class,
yes=0, no=1)))
### Next, let's investigate the LR's performance on the test set
pred.log.nnet = predict(fit.log.nnet, data.valid.scale)
table(Y.valid, pred.log.nnet,        ### Confusion matrix
dnn = c("Observed", "Predicted"))
(misclass.log.nnet = mean(pred.log.nnet != Y.valid)) ### Misclass rate
X.train.scale = as.matrix(data.train.scale[,-1])
Y.train = data.train.scale[,1]
X.valid.scale = as.matrix(data.valid.scale[,-1])
Y.valid = data.valid.scale[,1]
### Let's repeat our logistic regression analysis using the glmnet package.
fit.log.glmnet = glmnet(X.train.scale, Y.train, family = "multinomial")
head(Y.train)
X.train.scale
### Let's repeat our logistic regression analysis using the glmnet package.
fit.log.glmnet = glmnet(X.train.scale, Y.train, family = "multinomial")
# (a) Report a list of the variables included/excluded in each logit. Does
# the pattern seem somewhat consistent with the ANOVA results from
# earlier? Explain in a sentence.
X.train.scale = as.matrix(data.train.scale[,-19])
Y.train = data.train.scale[,19]
X.valid.scale = as.matrix(data.valid.scale[,-19])
Y.valid = data.valid.scale[,19]
### Let's repeat our logistic regression analysis using the glmnet package.
fit.log.glmnet = glmnet(X.train.scale, Y.train, family = "multinomial")
### Get predictions and investigate performance. The predict() function
### for glmnet() can give several different types of output. To get
### predicted values, set type="class". Remember to set s=0 for logistic
### regression.
pred.log.glmnet = predict(fit.log.glmnet, X.valid.scale, type = "class",
s = 0)
table(Y.valid, pred.log.glmnet, dnn = c("Observed", "Predicted"))
(misclass.log.glmnet = mean(Y.valid != pred.log.glmnet))
### Let's repeat our logistic regression analysis using the glmnet package.
fit.log.glmnet = cv.glmnet(X.train.scale, Y.train, family = "multinomial")
### Let's repeat our logistic regression analysis using the glmnet package.
#fit.log.glmnet = cv.glmnet(X.train.scale, Y.train, family = "multinomial")
all.LASSOs = cv.glmnet(X.train.scale, Y.train, family = "multinomial")
lambda.min = all.LASSOs$lambda.min
lambda.1se = all.LASSOs$lambda.1se
lambda.min
lambda.1se
### Get predictions and investigate performance. The predict() function
### for glmnet() can give several different types of output. To get
### predicted values, set type="class". Remember to set s=0 for logistic
### regression.
# pred.log.glmnet = predict(fit.log.glmnet, X.valid.scale, type = "class",
#                           s = 0)
pred.log.glmnet.min = predict(fit.log.glmnet, X.valid.scale, type = "class",
s = lambda.min)
pred.log.glmnet.1se = predict(fit.log.glmnet, X.valid.scale, type = "class",
s = lambda.1se)
# table(Y.valid, pred.log.glmnet, dnn = c("Observed", "Predicted"))
table(Y.valid, pred.log.glmnet.min, dnn = c("Observed", "Predicted"))
table(Y.valid, pred.log.glmnet.1se, dnn = c("Observed", "Predicted"))
(misclass.log.glmnet = mean(Y.valid != pred.log.glmnet.min))
(misclass.log.glmnet = mean(Y.valid != pred.log.glmnet.1se))
preg.log.glmnet.min
pred.log.glmnet.min
fit.log.glmnet
all.LASSOs
# table(Y.valid, pred.log.glmnet, dnn = c("Observed", "Predicted"))
table(Y.valid, pred.log.glmnet.min, dnn = c("Observed", "Predicted"))
summary(pred.log.glmnet.min)
summary(all.LASSOs)
summary(fit.log.glmnet)
summary(pred.log.glmnet.min)
coef(pred.log.glmnet.1se, s = lambda.min)
coef(pred.log.glmnet.1se, s = "lambda.min")
c<-coef(pred.log.glmnet.min,s='lambda.min',exact=TRUE)
c<-coef(pred.log.glmnet.min, s=lambda.min,exact=TRUE)
c<-coef(all.LASSOs, s=lambda.min,exact=TRUE)
inds<-which(c!=0)
variables<-row.names(c)[inds]
inds<-which(c!=0)
c<-coef(all.LASSOs, s="lambda.min",exact=TRUE, family="multinomial")
inds<-which(c!=0)
coef(all.LASSOs, s="lambda.min",exact=TRUE, family="multinomial")
lasso.coef = coef(all.LASSOs, s="lambda.min",exact=TRUE, family="multinomial")
lasso.coef
lasso.min.coef = coef(all.LASSOs, s="lambda.min",exact=TRUE, family="multinomial")
lasso.min.coef = coef(all.LASSOs, s="lambda.min",exact=TRUE, family="multinomial")
lasso.min.coef
lasso.1se.coef = coef(all.LASSOs, s="lambda.1se",exact=TRUE, family="multinomial")
lasso.1se.coef
(misclass.log.glmnet = mean(Y.valid != pred.log.glmnet.min))
(misclass.log.glmnet = mean(Y.valid != pred.log.glmnet.1se))
fit.CV.lasso = cv.glmnet(X.train.scale, Y.train, family = "multinomial")
lambda.min = fit.CV.lasso$lambda.min
lambda.1se = fit.CV.lasso$lambda.1se
coef(fit.CV.lasso, s = lambda.min)
coef(fit.CV.lasso, s = lambda.1se)
pred.lasso.min = predict(fit.CV.lasso, X.valid.scale, s = lambda.min,
type = "class")
pred.lasso.1se = predict(fit.CV.lasso, X.valid.scale, s = lambda.1se,
type = "class")
pred.lasso.min = predict(fit.CV.lasso, X.valid.scale, s = lambda.min,
type = "class")
pred.lasso.1se = predict(fit.CV.lasso, X.valid.scale, s = lambda.1se,
type = "class")
table(Y.valid, pred.lasso.min, dnn = c("Obs", "Pred"))
table(Y.valid, pred.lasso.1se, dnn = c("Obs", "Pred"))
(miss.lasso.min = mean(Y.valid != pred.lasso.min))
(miss.lasso.1se = mean(Y.valid != pred.lasso.1se))
scale.1 <- function(x1,x2){
for(col in 1:ncol(x1)){
a <- mean(x2[,col])
b <- sd(x2[,col])
x1[,col] <- (x1[,col]-a)/b
}
x1
}
X.train.DA = scale.1(data.train[,-1], data.train[,-1])
X.valid.DA = scale.1(data.valid[,-1], data.train[,-1])
##### 3. Run LDA on these data.
# (a) Make a colour plot of the classes against pairs of linear discriminants
scale.1 <- function(x1,x2){
for(col in 1:ncol(x1)){
a <- mean(x2[,col])
b <- sd(x2[,col])
x1[,col] <- (x1[,col]-a)/b
}
x1
}
X.train.DA = scale.1(data.train[,-1], data.train[,-1])
X.train.DA = scale.1(set1[,-19], set1[,-19])
X.valid.DA = scale.1(set2[,-1], set1[,-19])
X.valid.DA = scale.1(set2[,-19], set1[,-19])
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
fit.lda = lda(X.train.DA, Y.train)
class.col <- ifelse(set1$class==1,y=53,n= ifelse(set1$class==2,y=68,n=
ifelse(set1$class==3,y=203,n=464)))
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
class.col <- ifelse(set1$class==1,y=53,n= ifelse(set1$class==2,y=68,n=
ifelse(set1$class==3,y=203,n=464)))
class.col
set1
set1 <- vehdata [ which ( perm <= 3* nrow ( vehdata )/4) , ]
set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
class.col <- ifelse(set1$class==1,y=53,n= ifelse(set1$class==2,y=68,n=
ifelse(set1$class==3,y=203,n=464)))
class.co
class.col
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
class.col <- ifelse(set1$class==1,y=53,n= ifelse(set1$class==2,y=68,n=
ifelse(set1$class==3,y=203,n=464)))
class.co
class.col
set1
###### 1. Run logistic regression using multinom().
vehdata = read.csv("vehicle.csv")
set1 <- vehdata [ which ( perm <= 3* nrow ( vehdata )/4) , ]
set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
class.col <- ifelse(set1$class==1,y=53,n= ifelse(set1$class==2,y=68,n=
ifelse(set1$class==3,y=203,n=464)))
class.co
class.col
fit.lda = lda(X.train.DA, Y.train)
plot(fit.lda, col = class.col)
X.train.DA
pred.lda = predict(fit.lda, X.valid.DA)$class
table(Y.valid, pred.lda, dnn = c("Obs", "Pred"))
(miss.lda = mean(Y.valid != pred.lda))
fit.qda = qda(X.train.DA, Y.train)
pred.qda = predict(fit.qda, X.valid.DA)$class
table(Y.valid, pred.qda, dnn = c("Obs", "Pred"))
(miss.qda = mean(Y.valid != pred.qda))
library(dplyr)
library(MASS)   # For ridge regression
library(glmnet) # For LASSO
library(nnet) # Fits neural net models
library(rgl)
library(FNN)
source("Helper Functions.R")
set.seed(46685326, kind = "Mersenne-Twister")
###### 1. Get to know the data
# (a) Read the data and print a summary.
vehdata = read.csv("vehicle.csv")
library(dplyr)
library(MASS)   # For ridge regression
library(glmnet) # For LASSO
library(nnet) # Fits neural net models
library(rgl)
library(FNN)
library(mgcv)   # For GAM
library(klaR)   # For naive Bayes
source("Helper Functions.R")
library(dplyr)
library(MASS)   # For ridge regression
library(glmnet) # For LASSO
library(nnet) # Fits neural net models
library(rgl)
library(FNN)
source("Helper Functions.R")
### Some of our code will be random, so we have to set the seed.
### Use Mersenne-Twister for compatibility.
set.seed(46685326, kind = "Mersenne-Twister")
###### 1. Get to know the data
# (a) Read the data and print a summary.
vehdata = read.csv("vehicle.csv")
print(summary(vehdata))
##### Run a KNN analysis on the training data using m = 1.
# (a) Show the confusion matrix for the test data. Comment on how well
# separated the four classes are. In particular, are there classes that are
# easier/harder to separate?
X.train.raw = set1[,-19]
X.valid.raw = set2[,-19]
Y.train = as.matrix(set1[,19])
Y.valid = as.matrix(set2[,19])
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1,x2){
for(col in 1:ncol(x1)){
a <- mean(x2[,col])
b <- sd(x2[,col])
x1[,col] <- (x1[,col]-a)/b
}
x1
}
head(vehdata)
quality.fact.raw = factor(data$quality, levels = c("2D", "4D", "BUS", "VAN"))
quality.fact.raw = factor(vehdata$class, levels = c("2D", "4D", "BUS", "VAN"))
head(quality.fact.raw)
quality.fact.1 = as.numeric(quality.fact.raw)
head(quality.fact.1)
quality.fact.0 = quality.fact.1 - 1
setwd("C:/Users/injoo/OneDrive/Desktop/SFU/STAT 452/Tutorial/Lecture19_20")
### Read-in and process the data
source("Read Wine Data - Class.R")
### Read-in and process the data
source("Read Wine Data - Class.R")
### Activate packages
library(mgcv)   # For GAM
library(klaR)   # For naive Bayes
### Set random seed, using Mersenne-Twister for compatibility.
set.seed(46536737, kind = "Mersenne-Twister")
head(data)
### To fit GAM models, we need to represent the different classes numerically,
### with class labels starting at 0. We can do this using the factor()
### function. This function converts a list of character strings to a factor
### object, which we can then convert to numbered labels. When using the
### factor function, it is convenient to set the order of the levels, so that
### you know what each number will represent.
### We convert from a factor object to its numeric labels using as.numeric().
### These numeric labels start at 1. To get labels starting at 0, we can just
### subtract 1.
quality.fact.raw = factor(data$quality, levels = c("low", "med", "high"))
head(quality.fact.raw)
quality.fact.raw = factor(vehdata$class)
head(quality.fact.raw)
quality.fact.1 = as.numeric(quality.fact.raw)
head(quality.fact.1)
quality.fact.0 = quality.fact.1 - 1
qquality.fact.0
quality.fact.0
perm <- sample (x= nrow ( vehdata ))
set1 <- vehdata [ which ( perm <= 3* nrow ( vehdata )/4) , ]
set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
head(set1)
quality.fact.raw = factor(set1$class)
head(quality.fact.raw)
quality.fact.1 = as.numeric(quality.fact.raw)
head(quality.fact.1)
quality.fact.0 = quality.fact.1 - 1
quality.fact.raw = factor(set2$class)
head(quality.fact.raw)
quality.fact.1 = as.numeric(quality.fact.raw)
head(quality.fact.1)
quality.fact.0 = quality.fact.1 - 1
#Change class in set1
set1$class = set1$class - 1
head(set1)
#Change class in set2
set2$class = set2$class - 1
head(set2)
##### Split the data using the code below, where set1 will be the training set for future
# analyses and set2 the test set:
perm <- sample (x= nrow ( vehdata ))
set1 <- vehdata [ which ( perm <= 3* nrow ( vehdata )/4) , ]
set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
haed(set1)
head(set1)
#Change class in set1
set1$class = set1$class - 1
#Change class in set2
set2$class = set2$class - 1
set1
X.train.raw = set1[,-19]
X.valid.raw = set2[,-19]
Y.train = as.matrix(set1[,19])
Y.valid = as.matrix(set2[,19])
### To do naive Bayes in R, we need the response variable to be a factor
### object (unlike GAM). Let's re-split the data using the same indices we
### computed above and convert our response to a factor. I like to also
### explicitly assign an order to facors using the levels input.
perm <- sample (x= nrow ( vehdata ))
set1 <- vehdata [ which ( perm <= 3* nrow ( vehdata )/4) , ]
set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
X.train = set1[,-19]
X.valid = set2[,-19]
Y.train = factor(set1[,19], levels = labels=c("2D", "4D", "BUS", "VAN"))
Y.train = factor(set1[,19], levels = c("2D", "4D", "BUS", "VAN"))
Y.valid = factor(set2[,19], levels = c("2D", "4D", "BUS", "VAN"))
### We fit naive Bayes models using the NaiveBayes() function from the klaR
### package. This function uses predictor matrix/response vector syntax. You
### can also specify if you want to use kernel density estimation by setting
### usekernel=TRUE. Setting this to false uses the normal distribution for
### each predictor.
fit.NB.userkernel = NaiveBayes(X.train, Y.train, usekernel = T)
X.train
head(X.train)
head(Y.train)
head(set1)
Y.train
Y.train = factor(set1[,19], levels = c("2D", "4D", "BUS", "VAN"))
Y.train = set1[, 19]
Y.train
Y.train = as.factor(Y.train)
Y.train
Y.valid = set2[, -19]
Y.valid = as.factor(Y.valid)
Y.valid
Y.valid = set2[, 19]
Y.valid = as.factor(Y.valid)
Y.valid
### We fit naive Bayes models using the NaiveBayes() function from the klaR
### package. This function uses predictor matrix/response vector syntax. You
### can also specify if you want to use kernel density estimation by setting
### usekernel=TRUE. Setting this to false uses the normal distribution for
### each predictor.
fit.NB.userkernel = NaiveBayes(X.train, Y.train, usekernel = T)
fit.NB.notuserkernel = NaiveBayes(X.train, Y.train, usekernel = F)
### We can plot the kernel density estimates. This gives us a separate plot
### for each predictor, so 6 total plots. Best to use par() to get all
### these plots simultaneously.
par(mfrow = c(3,6)) # Set plotting to 3x6
plot(fit.NB.userkernel)
### We fit naive Bayes models using the NaiveBayes() function from the klaR
### package. This function uses predictor matrix/response vector syntax. You
### can also specify if you want to use kernel density estimation by setting
### usekernel=TRUE. Setting this to false uses the normal distribution for
### each predictor.
fit.NB.userkernel = NaiveBayes(X.train, Y.train, usekernel = T)
fit.NB.notuserkernel = NaiveBayes(X.train, Y.train, usekernel = F)
### We can plot the kernel density estimates. This gives us a separate plot
### for each predictor, so 6 total plots. Best to use par() to get all
### these plots simultaneously.
par(mfrow = c(3,6)) # Set plotting to 3x6
plot(fit.NB.userkernel)
# 1. Run the version with kernel density estimation on the original variables first
fit.NB.original = NaiveBayes(vehdata[,-19], vehdata[,19], usekernel = T)
# 1. Run the version with kernel density estimation on the original variables first
fit.NB.original = NaiveBayes(vehdata[,-19], as.factor(vehdata[,19]), usekernel = T)
par(mfrow = c(3,6)) # Set plotting to 3x6
plot(fit.NB.original)
perm <- sample (x= nrow ( vehdata ))
set1 <- vehdata [ which ( perm <= 3* nrow ( vehdata )/4) , ]
set2 <- vehdata [ which ( perm > 3* nrow ( vehdata )/4) , ]
X.train = set1[,-19]
X.valid = set2[,-19]
Y.train = set1[, 19]
Y.train = as.factor(Y.train)
Y.valid = set2[, 19]
Y.valid = as.factor(Y.valid)
### Next, let's get predictions, their corresponding confusion matrix and
### the misclassification rate. Predictions from NaiveBayes models give
### predicted class labels and probabilities, so we have to extract the
### class labels using $class
pred.NB.userkernel.raw = predict(fit.NB.userkernel, X.valid)
pred.NB = pred.NB.userkernel.raw$class
table(Y.valid, pred.NB, dnn = c("Obs", "Pred"))
(mis.NB = mean(Y.valid != pred.NB))
#Kernel
pred.NB.notuserkernel.raw = predict(fit.NB.notuserkernel, X.valid)
#Kernel
pred.NB.notuserkernel.raw = predict(fit.NB.notuserkernel, X.valid)
pred.NB = pred.NB.notuserkernel.raw$class
table(Y.valid, pred.NB, dnn = c("Obs", "Pred"))
(mis.NB = mean(Y.valid != pred.NB))
#####PC
### It can be helpful with naive Bayes to first do a principal components
### analysis (see Lecture 7). We will do PCA on the training set, then
### apply the same transformation to the validation set using the predict()
### function. Remember to scale the predictors by setting scale. to true.
fit.PCA = prcomp(X.train, scale. = T)
X.train.PC = fit.PCA$x  # Extract the PCs
X.train.PC
#####PC
### It can be helpful with naive Bayes to first do a principal components
### analysis (see Lecture 7). We will do PCA on the training set, then
### apply the same transformation to the validation set using the predict()
### function. Remember to scale the predictors by setting scale. to true.
fit.PCA = prcomp(X.train, scale. = T)
X.train.PC = fit.PCA$x  # Extract the PCs
X.valid.PC = predict(fit.PCA, set2)
### Now we can use the NaiveBayes() function in exactly the same way as
### above.
fit.NB.PC.userkernel = NaiveBayes(X.train.PC, Y.train, usekernel = T)
fit.NB.PC.notuserkernel = NaiveBayes(X.train.PC, Y.train, usekernel = F)
#Kernel
pred.NB.userkernel.raw = predict(fit.NB.PC.userkernel, X.valid)
### Now we can use the NaiveBayes() function in exactly the same way as
### above.
fit.NB.PC.userkernel = NaiveBayes(X.train.PC, Y.train, usekernel = T)
fit.NB.PC.notuserkernel = NaiveBayes(X.train.PC, Y.train, usekernel = F)
#Kernel
pred.NB.userkernel.raw = predict(fit.NB.PC.userkernel, X.valid)
pred.NB = pred.NB.userkernel.raw$class
table(Y.valid, pred.NB, dnn = c("Obs", "Pred"))
(mis.NB = mean(Y.valid != pred.NB))
### Now we can use the NaiveBayes() function in exactly the same way as
### above.
fit.NB.PC.userkernel = NaiveBayes(X.train.PC, Y.train, usekernel = T)
fit.NB.PC.userkernel
fit.NB.PC.notuserkernel = NaiveBayes(X.train.PC, Y.train, usekernel = F)
#Kernel
pred.NB.userkernel.raw = predict(fit.NB.PC.userkernel, X.valid)
#Kernel
pred.NB.userkernel.raw = predict(fit.NB.PC.userkernel, X.valid.PC)
pred.NB = pred.NB.userkernel.raw$class
(mis.NB = mean(Y.valid != pred.NB))
#NOT Kernel
pred.NB.notuserkernel.raw = predict(fit.NB.notuserkernel, X.valid.PC)
pred.NB = pred.NB.notuserkernel.raw$class
table(Y.valid, pred.NB, dnn = c("Obs", "Pred"))
(mis.NB = mean(Y.valid != pred.NB))
fit.NB.PC.notuserkernel = NaiveBayes(X.train.PC, Y.train, usekernel = F)
#Kernel
pred.NB.PC.userkernel.raw = predict(fit.NB.PC.userkernel, X.valid.PC)
pred.NB = pred.NB.userkernel.PC.raw$class
#Kernel
pred.NB.PC.userkernel.raw = predict(fit.NB.PC.userkernel, X.valid.PC)
pred.NB = pred.NB.PC.userkernel.raw$class
(mis.NB = mean(Y.valid != pred.NB))
#NOT Kernel
pred.NB.PC.notuserkernel.raw = predict(fit.NB.PC.notuserkernel, X.valid.PC)
pred.NB = pred.NB.PC.notuserkernel.raw$class
(mis.NB = mean(Y.valid != pred.NB))
#NOT Kernel
pred.NB.notuserkernel.raw = predict(fit.NB.notuserkernel, X.valid)
pred.NB = pred.NB.notuserkernel.raw$class
(mis.NB = mean(Y.valid != pred.NB))
